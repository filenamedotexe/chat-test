
> chat-application@0.1.0 dev
> next dev

  ▲ Next.js 14.2.13
  - Local:        http://localhost:3000
  - Environments: .env.local, .env

 ✓ Starting...
 ✓ Ready in 1063ms
 ✓ Compiled /middleware in 94ms (216 modules)
 ○ Compiling / ...
 ✓ Compiled /api/support-chat/conversations in 2.3s (2157 modules)
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 HEAD / 200 in 2537ms
 ✓ Compiled in 226ms (899 modules)
 GET /api/support-chat/conversations?limit=3 200 in 582ms
 ✓ Compiled /login in 171ms (2143 modules)
 GET /login 200 in 217ms
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 GET /api/support-chat/conversations?limit=3 200 in 233ms
 ✓ Compiled /_not-found in 118ms (2146 modules)
 GET /api/support-chat/conversations?limit=3 404 in 159ms
 ✓ Compiled /_error in 446ms (2371 modules)
 GET /login 404 in 494ms
 GET /login 404 in 494ms
 GET /api/support-chat/conversations?limit=3 404 in 37ms
 GET /api/support-chat/conversations?limit=3 404 in 13ms
 ✓ Compiled /api/auth/[...nextauth] in 111ms (1251 modules)
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 GET /api/auth/session 200 in 332ms
 GET /api/auth/session 200 in 21ms
 GET /api/support-chat/conversations?limit=3 200 in 280ms
 GET /api/support-chat/conversations?limit=3 200 in 186ms
 GET /api/support-chat/conversations?limit=3 200 in 136ms
 GET /api/support-chat/conversations?limit=3 200 in 145ms
 GET /api/support-chat/conversations?limit=3 200 in 120ms
 GET /api/support-chat/conversations?limit=3 200 in 208ms
 GET /api/support-chat/conversations?limit=3 200 in 422ms
 GET /api/support-chat/conversations?limit=3 200 in 227ms
 GET /api/auth/session 200 in 14ms
 GET /api/auth/session 200 in 5ms
 GET /api/support-chat/conversations?limit=3 200 in 119ms
 GET /api/support-chat/conversations?limit=3 200 in 39ms
 ○ Compiling /chat ...
 ✓ Compiled /chat in 527ms (2418 modules)
 ✓ Compiled /support in 287ms (2500 modules)
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 GET /support?_rsc=uk94b 200 in 216ms
 GET /api/support-chat/conversations?unread_only=true 200 in 68ms
 GET /api/support-chat/conversations?page=1&limit=20 200 in 82ms
 GET /api/support-chat/conversations?unread_only=true 200 in 40ms
 GET /api/support-chat/conversations?page=1&limit=20 200 in 35ms
 GET /api/support-chat/conversations?page=1&limit=20 200 in 37ms
 GET /api/support-chat/conversations?page=1&limit=20 200 in 38ms
 ✓ Compiled /profile in 158ms (2521 modules)
 ✓ Compiled /api/user/permissions in 88ms (1388 modules)
 ✓ Compiled (1393 modules)
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 GET /api/user/permissions 200 in 433ms
 GET /api/user/permissions 200 in 300ms
 GET /api/user/activity 200 in 593ms
 GET /api/user/activity 200 in 215ms
 GET /api/user/profile 200 in 965ms
 GET /api/user/profile 200 in 582ms
 ✓ Compiled /settings in 231ms (2562 modules)
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
 GET /settings?_rsc=x4clf 200 in 10ms
 ○ Compiling /api/chat-langchain ...
 ✓ Compiled /api/chat-langchain in 690ms (1978 modules)
🚨 LANGCHAIN API CALLED - Handoff detection enabled!
[next-auth][warn][DEBUG_ENABLED] 
https://next-auth.js.org/warnings#debug_enabled
🔍 Checking handoff for message: hey im peter
🔍 Handoff result: { shouldHandoff: false }
Memory loaded for session session-1753151532801-qjycts8ou (buffer): {
  "history": []
}
[32m[chain/start][39m [[90m[1m1:chain:ConversationChain[22m[39m] Entering Chain run with input: {
  "input": "hey im peter",
  "history": []
}
[32m[llm/start][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] Entering LLM run with input: {
  "messages": [
    [
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "SystemMessage"
        ],
        "kwargs": {
          "content": "You are a helpful assistant created by Neon.tech and Aceternity. You have access to the full conversation history and can remember previous interactions within this chat session. When users refer to earlier parts of the conversation, you can recall and reference that information. Your job is to answer questions asked by the user in a polite and respectful manner. Always answer in markdown.",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "hey im peter",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      }
    ]
  ]
}
LLM finished, full content: Hello Peter! How can I assist you today?
Message added to memory (not persisted individually): HumanMessage {
  "content": "hey im peter",
  "additional_kwargs": {},
  "response_metadata": {}
}
Message added to memory (not persisted individually): AIMessage {
  "content": "Hello Peter! How can I assist you today?",
  "additional_kwargs": {},
  "response_metadata": {},
  "tool_calls": [],
  "invalid_tool_calls": []
}
 POST /api/chat-langchain 200 in 2247ms
Conversation saved to database
[36m[llm/end][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] [1.31s] Exiting LLM run with output: {
  "generations": [
    [
      {
        "text": "Hello Peter! How can I assist you today?",
        "generationInfo": {
          "prompt": 0,
          "completion": 0,
          "finish_reason": "stop",
          "system_fingerprint": "fp_de235176ee",
          "model_name": "gpt-4-turbo-2024-04-09",
          "service_tier": "default"
        },
        "message": {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain_core",
            "messages",
            "AIMessageChunk"
          ],
          "kwargs": {
            "content": "Hello Peter! How can I assist you today?",
            "additional_kwargs": {},
            "response_metadata": {
              "estimatedTokenUsage": {
                "promptTokens": 90,
                "completionTokens": 10,
                "totalTokens": 100
              },
              "prompt": 0,
              "completion": 0,
              "finish_reason": "stop",
              "system_fingerprint": "fp_de235176ee",
              "model_name": "gpt-4-turbo-2024-04-09",
              "service_tier": "default",
              "usage": {
                "prompt_tokens": 86,
                "completion_tokens": 10,
                "total_tokens": 96,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            },
            "tool_call_chunks": [],
            "id": "chatcmpl-BvzYrP3H7apvMhY3FHYNJetn7W0oy",
            "usage_metadata": {
              "input_tokens": 86,
              "output_tokens": 10,
              "total_tokens": 96,
              "input_token_details": {
                "audio": 0,
                "cache_read": 0
              },
              "output_token_details": {
                "audio": 0,
                "reasoning": 0
              }
            },
            "tool_calls": [],
            "invalid_tool_calls": []
          }
        }
      }
    ]
  ],
  "llmOutput": {
    "estimatedTokenUsage": {
      "promptTokens": 90,
      "completionTokens": 10,
      "totalTokens": 100
    }
  }
}
[36m[chain/end][39m [[90m[1m1:chain:ConversationChain[22m[39m] [1.31s] Exiting Chain run with output: {
  "response": "Hello Peter! How can I assist you today?"
}
🚨 LANGCHAIN API CALLED - Handoff detection enabled!
🔍 Checking handoff for message: whats my name
🔍 Handoff result: { shouldHandoff: false }
Memory loaded for session session-1753151532801-qjycts8ou (buffer): {
  "history": [
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "hey im peter",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Hello Peter! How can I assist you today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    }
  ]
}
[32m[chain/start][39m [[90m[1m1:chain:ConversationChain[22m[39m] Entering Chain run with input: {
  "input": "whats my name",
  "history": [
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "hey im peter",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Hello Peter! How can I assist you today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    }
  ]
}
[32m[llm/start][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] Entering LLM run with input: {
  "messages": [
    [
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "SystemMessage"
        ],
        "kwargs": {
          "content": "You are a helpful assistant created by Neon.tech and Aceternity. You have access to the full conversation history and can remember previous interactions within this chat session. When users refer to earlier parts of the conversation, you can recall and reference that information. Your job is to answer questions asked by the user in a polite and respectful manner. Always answer in markdown.",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "hey im peter",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "AIMessage"
        ],
        "kwargs": {
          "content": "Hello Peter! How can I assist you today?",
          "tool_calls": [],
          "invalid_tool_calls": [],
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "whats my name",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      }
    ]
  ]
}
LLM finished, full content: Your name is Peter. How can I help you further today?
Message added to memory (not persisted individually): HumanMessage {
  "content": "whats my name",
  "additional_kwargs": {},
  "response_metadata": {}
}
Message added to memory (not persisted individually): AIMessage {
  "content": "Your name is Peter. How can I help you further today?",
  "additional_kwargs": {},
  "response_metadata": {},
  "tool_calls": [],
  "invalid_tool_calls": []
}
 POST /api/chat-langchain 200 in 1100ms
Conversation saved to database
[36m[llm/end][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] [985ms] Exiting LLM run with output: {
  "generations": [
    [
      {
        "text": "Your name is Peter. How can I help you further today?",
        "generationInfo": {
          "prompt": 0,
          "completion": 0,
          "finish_reason": "stop",
          "system_fingerprint": "fp_de235176ee",
          "model_name": "gpt-4-turbo-2024-04-09",
          "service_tier": "default"
        },
        "message": {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain_core",
            "messages",
            "AIMessageChunk"
          ],
          "kwargs": {
            "content": "Your name is Peter. How can I help you further today?",
            "additional_kwargs": {},
            "response_metadata": {
              "estimatedTokenUsage": {
                "promptTokens": 113,
                "completionTokens": 13,
                "totalTokens": 126
              },
              "prompt": 0,
              "completion": 0,
              "finish_reason": "stop",
              "system_fingerprint": "fp_de235176ee",
              "model_name": "gpt-4-turbo-2024-04-09",
              "service_tier": "default",
              "usage": {
                "prompt_tokens": 108,
                "completion_tokens": 13,
                "total_tokens": 121,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            },
            "tool_call_chunks": [],
            "id": "chatcmpl-BvzYwsiAV2eihtqmuYxr6vJylWwr6",
            "usage_metadata": {
              "input_tokens": 108,
              "output_tokens": 13,
              "total_tokens": 121,
              "input_token_details": {
                "audio": 0,
                "cache_read": 0
              },
              "output_token_details": {
                "audio": 0,
                "reasoning": 0
              }
            },
            "tool_calls": [],
            "invalid_tool_calls": []
          }
        }
      }
    ]
  ],
  "llmOutput": {
    "estimatedTokenUsage": {
      "promptTokens": 113,
      "completionTokens": 13,
      "totalTokens": 126
    }
  }
}
[36m[chain/end][39m [[90m[1m1:chain:ConversationChain[22m[39m] [985ms] Exiting Chain run with output: {
  "response": "Your name is Peter. How can I help you further today?"
}
🚨 LANGCHAIN API CALLED - Handoff detection enabled!
🔍 Checking handoff for message: do i ahve any service tickets open
🔍 Handoff result: { shouldHandoff: false }
Memory loaded for session session-1753151532801-qjycts8ou (buffer): {
  "history": [
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "hey im peter",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Hello Peter! How can I assist you today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "whats my name",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Your name is Peter. How can I help you further today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    }
  ]
}
[32m[chain/start][39m [[90m[1m1:chain:ConversationChain[22m[39m] Entering Chain run with input: {
  "input": "do i ahve any service tickets open",
  "history": [
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "hey im peter",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Hello Peter! How can I assist you today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "HumanMessage"
      ],
      "kwargs": {
        "content": "whats my name",
        "additional_kwargs": {},
        "response_metadata": {}
      }
    },
    {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "messages",
        "AIMessage"
      ],
      "kwargs": {
        "content": "Your name is Peter. How can I help you further today?",
        "tool_calls": [],
        "invalid_tool_calls": [],
        "additional_kwargs": {},
        "response_metadata": {}
      }
    }
  ]
}
[32m[llm/start][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] Entering LLM run with input: {
  "messages": [
    [
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "SystemMessage"
        ],
        "kwargs": {
          "content": "You are a helpful assistant created by Neon.tech and Aceternity. You have access to the full conversation history and can remember previous interactions within this chat session. When users refer to earlier parts of the conversation, you can recall and reference that information. Your job is to answer questions asked by the user in a polite and respectful manner. Always answer in markdown.",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "hey im peter",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "AIMessage"
        ],
        "kwargs": {
          "content": "Hello Peter! How can I assist you today?",
          "tool_calls": [],
          "invalid_tool_calls": [],
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "whats my name",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "AIMessage"
        ],
        "kwargs": {
          "content": "Your name is Peter. How can I help you further today?",
          "tool_calls": [],
          "invalid_tool_calls": [],
          "additional_kwargs": {},
          "response_metadata": {}
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain_core",
          "messages",
          "HumanMessage"
        ],
        "kwargs": {
          "content": "do i ahve any service tickets open",
          "additional_kwargs": {},
          "response_metadata": {}
        }
      }
    ]
  ]
}
LLM finished, full content: I don't have access to personal data or the ability to check service tickets. You might need to check directly on the website or contact customer service of the relevant organization to inquire about any open service tickets. How else may I assist you today?
Message added to memory (not persisted individually): HumanMessage {
  "content": "do i ahve any service tickets open",
  "additional_kwargs": {},
  "response_metadata": {}
}
Message added to memory (not persisted individually): AIMessage {
  "content": "I don't have access to personal data or the ability to check service tickets. You might need to check directly on the website or contact customer service of the relevant organization to inquire about any open service tickets. How else may I assist you today?",
  "additional_kwargs": {},
  "response_metadata": {},
  "tool_calls": [],
  "invalid_tool_calls": []
}
 POST /api/chat-langchain 200 in 1849ms
Conversation saved to database
[36m[llm/end][39m [[90m1:chain:ConversationChain > [1m2:llm:ChatOpenAI[22m[39m] [1.57s] Exiting LLM run with output: {
  "generations": [
    [
      {
        "text": "I don't have access to personal data or the ability to check service tickets. You might need to check directly on the website or contact customer service of the relevant organization to inquire about any open service tickets. How else may I assist you today?",
        "generationInfo": {
          "prompt": 0,
          "completion": 0,
          "finish_reason": "stop",
          "system_fingerprint": "fp_de235176ee",
          "model_name": "gpt-4-turbo-2024-04-09",
          "service_tier": "default"
        },
        "message": {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain_core",
            "messages",
            "AIMessageChunk"
          ],
          "kwargs": {
            "content": "I don't have access to personal data or the ability to check service tickets. You might need to check directly on the website or contact customer service of the relevant organization to inquire about any open service tickets. How else may I assist you today?",
            "additional_kwargs": {},
            "response_metadata": {
              "estimatedTokenUsage": {
                "promptTokens": 143,
                "completionTokens": 49,
                "totalTokens": 192
              },
              "prompt": 0,
              "completion": 0,
              "finish_reason": "stop",
              "system_fingerprint": "fp_de235176ee",
              "model_name": "gpt-4-turbo-2024-04-09",
              "service_tier": "default",
              "usage": {
                "prompt_tokens": 137,
                "completion_tokens": 49,
                "total_tokens": 186,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            },
            "tool_call_chunks": [],
            "id": "chatcmpl-BvzZ8HHT0f5xra3ayj0sBflFj1elx",
            "usage_metadata": {
              "input_tokens": 137,
              "output_tokens": 49,
              "total_tokens": 186,
              "input_token_details": {
                "audio": 0,
                "cache_read": 0
              },
              "output_token_details": {
                "audio": 0,
                "reasoning": 0
              }
            },
            "tool_calls": [],
            "invalid_tool_calls": []
          }
        }
      }
    ]
  ],
  "llmOutput": {
    "estimatedTokenUsage": {
      "promptTokens": 143,
      "completionTokens": 49,
      "totalTokens": 192
    }
  }
}
[36m[chain/end][39m [[90m[1m1:chain:ConversationChain[22m[39m] [1.58s] Exiting Chain run with output: {
  "response": "I don't have access to personal data or the ability to check service tickets. You might need to check directly on the website or contact customer service of the relevant organization to inquire about any open service tickets. How else may I assist you today?"
}
