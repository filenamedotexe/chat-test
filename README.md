# Neon x Aceternity Chatbot Template - LangChain Enhanced

A modern, interactive chatbot template built with Next.js, LangChain, AI SDK, Aceternity UI, and Neon's serverless Postgres.

![Banner](https://neon-chatbot.vercel.app/banner.png)

## üöÄ New LangChain Features

- üß† **Dual Memory Systems**: Choose between Buffer Memory (exact history) or Summary Memory (condensed conversations)
- üé≠ **8 Personality Templates**: Switch between Default, Technical Expert, Creative Writer, Teacher, Concise Expert, Data Analyst, Coach, and Socratic Questioner
- üíæ **Persistent Conversations**: Automatic session management with database-backed memory
- ‚ö° **Optimized Streaming**: ~745ms to first token with 15 tokens/second throughput
- üõ°Ô∏è **Robust Error Handling**: Retry logic, rate limit handling, and graceful error recovery
- üìä **Performance Optimized**: Database indexes and query optimization for scalability

## Features

- ü§ñ Real-time streaming responses with LangChain
- üíæ Persistent chat history storage with Neon serverless Postgres
- ‚ú® Beautiful UI components from Aceternity UI
- üé® Fully customizable with Tailwind CSS
- üì± Responsive design for all devices
- ‚ö° Built on Next.js 14 with App Router
- üîÑ Automatic memory management with conversation context

## Prerequisites

- Node.js 18+ 
- A [Neon](https://neon.tech/) account to create a Postgres database
- An [OpenAI](https://openai.com/) API key

## Getting Started

1. Clone the repository:

```bash
git clone https://github.com/neondatabase/neon-chatbot.git
cd neon-chatbot-template
```

2. Install dependencies:
```bash
npm install
# or
yarn install
# or
pnpm install
```

3. Create a `.env.local` file in the root directory with the following variables:
```bash
DATABASE_URL="your-neon-database-url"
OPENAI_API_KEY="your-openai-api-key"
```

4. Set up the database schema (automatic via API or run manually):
```sql
CREATE TABLE IF NOT EXISTS chat_history (
  id SERIAL PRIMARY KEY,
  user_message TEXT NOT NULL,
  assistant_message TEXT NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  session_id VARCHAR(255),
  metadata JSONB
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_chat_history_session_id ON chat_history(session_id);
CREATE INDEX IF NOT EXISTS idx_chat_history_created_at ON chat_history(created_at DESC);
```

5. Run the development server:
```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## üéÆ Using the Chatbot

### Memory Types
- **Buffer Memory**: Stores exact conversation history, ideal for short conversations
- **Summary Memory**: Creates condensed summaries, perfect for long conversations to save tokens

### Personality Templates
Click the settings icon (‚öôÔ∏è) in the chat interface to:
- Switch between 8 different AI personalities
- Toggle between Buffer and Summary memory
- Adjust token limits for summary memory
- View your current session ID

### API Endpoints

- `POST /api/chat-langchain` - Main chat endpoint with LangChain integration
- `GET /api/prompts` - Get available personality templates
- `GET /api/memory?sessionId=xxx` - Retrieve conversation history
- `POST /api/setup-database` - Automatically set up database schema

## Project Structure

- `/app` - Next.js 14 app directory containing routes and layouts
- `/components` - Reusable UI components including the enhanced chat bubble
- `/lib/langchain` - LangChain configuration, memory management, and prompt templates
- `/public` - Static assets and test utilities
- `/styles` - Global styles and Tailwind CSS configuration

## Key Technologies

- [Next.js](https://nextjs.org/) - React framework
- [LangChain](https://langchain.com/) - LLM application framework
- [Neon](https://neon.tech/) - Serverless Postgres database
- [OpenAI](https://openai.com/) - GPT-4 language model
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [Framer Motion](https://www.framer.com/motion/) - Animation library
- [Aceternity UI](https://ui.aceternity.com/) - UI components

## Performance Metrics

- **First Token Latency**: ~745ms average
- **Streaming Throughput**: ~15 tokens/second
- **Database Query Time**: ~240ms for history retrieval
- **Memory Comparison**: Summary memory 73% faster than buffer for long conversations

## Deployment

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new).

1. Push your code to a GitHub repository
2. Import your repository to Vercel
3. Add your environment variables in the Vercel dashboard
4. Deploy!

### Environment Variables for Production
```
DATABASE_URL=your-neon-database-url
OPENAI_API_KEY=your-openai-api-key
```

## Advanced Configuration

### Custom Prompt Templates
Add new personalities in `/lib/langchain/prompts.ts`:

```typescript
{
  id: "custom",
  name: "Custom Assistant",
  description: "Your custom personality",
  prompt: "Your custom system prompt...",
  icon: "üéØ"
}
```

### Database Optimization
Run the optimization queries in `/lib/langchain/optimize-db.sql` for better performance at scale.

## Troubleshooting

- **Streaming not working**: Ensure your OpenAI API key has access to streaming endpoints
- **Memory not persisting**: Check database connection and run setup-database endpoint
- **Slow responses**: Consider switching to Summary Memory for long conversations

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Acknowledgments

- [LangChain](https://langchain.com/) for the powerful LLM framework
- [Aceternity UI](https://ui.aceternity.com/) for the beautiful UI components
- [Neon.tech](https://neon.tech/) for the serverless Postgres database

## License

MIT License - feel free to use this template for your own projects!